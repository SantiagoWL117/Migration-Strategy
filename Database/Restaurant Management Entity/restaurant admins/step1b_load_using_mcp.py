#!/usr/bin/env python3
"""
Step 1b: Load V1 Data into Staging using parsed SQL dump
Excludes BLOB data - handled in Step 5
"""

import re
import json

# Read the SQL dump
print("=" * 80)
print("  Step 1b: Load V1 restaurant_admins Data into Staging")
print("=" * 80)
print()

dump_file = "Database/Restaurant Management Entity/restaurant admins/dumps/menuca_v1_restaurant_admins.sql"

print("[1/5] Reading dump file...")
with open(dump_file, 'r', encoding='utf-8', errors='ignore') as f:
    content = f.read()

print("[OK] File read successfully")
print()

# Extract INSERT statement
print("[2/5] Extracting INSERT statement...")
match = re.search(r'INSERT INTO `restaurant_admins` VALUES (.+?);', content, re.DOTALL)

if not match:
    print("[ERROR] Could not find INSERT statement")
    exit(1)

values_string = match.group(1)
print("[OK] INSERT statement found")
print()

# Parse records more carefully
print("[3/5] Parsing records...")

# Split by "),(" but be careful with nested structures
records_raw = []
current = ""
depth = 0
in_string = False
escape_next = False

for char in values_string:
    if escape_next:
        current += char
        escape_next = False
        continue
    
    if char == '\\':
        current += char
        escape_next = True
        continue
    
    if char == "'" and not escape_next:
        in_string = not in_string
        current += char
        continue
    
    if not in_string:
        if char == '(':
            depth += 1
        elif char == ')':
            depth -= 1
            if depth == 0:
                records_raw.append(current)
                current = ""
                continue
    
    if depth > 0:
        current += char

print(f"[OK] Found {len(records_raw)} records")
print()

# Generate PostgreSQL INSERT statements
print("[4/5] Generating PostgreSQL INSERT statements...")

sql_output = []
sql_output.append("-- Step 1b: Load V1 Data (WITHOUT BLOB)")
sql_output.append("-- Generated by: step1b_load_using_mcp.py")
sql_output.append("")
sql_output.append("BEGIN;")
sql_output.append("")
sql_output.append("-- Clear existing data (idempotent)")
sql_output.append("TRUNCATE TABLE staging.v1_restaurant_admin_users;")
sql_output.append("")

def parse_mysql_value(value):
    """Parse MySQL value to PostgreSQL"""
    value = value.strip()
    if value.upper() == 'NULL':
        return 'NULL'
    if value.startswith("'") and value.endswith("'"):
        # Escape single quotes for PostgreSQL
        value = value.replace("''", "'")
        value = value.replace("\\'", "''")
        return value
    if value.startswith('_binary'):
        return 'NULL'  # Skip BLOB
    return value

processed = 0
skipped = 0

for record in records_raw:
    try:
        # Split fields carefully
        fields = []
        current_field = ""
        in_quotes = False
        escape = False
        
        for char in record:
            if escape:
                current_field += char
                escape = False
                continue
            
            if char == '\\':
                current_field += char
                escape = True
                continue
            
            if char == "'":
                in_quotes = not in_quotes
                current_field += char
                continue
            
            if char == ',' and not in_quotes:
                fields.append(current_field)
                current_field = ""
                continue
            
            current_field += char
        
        if current_field:
            fields.append(current_field)
        
        if len(fields) < 11:
            skipped += 1
            continue
        
        # Extract fields
        # MySQL structure: id, admin_user_id, password, fname, lname, email, user_type, restaurant, 
        #                  lastlogin, activeUser, loginCount, _binary'...', ...
        legacy_admin_id = parse_mysql_value(fields[0])
        legacy_restaurant_id = parse_mysql_value(fields[7])  # restaurant field
        fname = parse_mysql_value(fields[3])
        lname = parse_mysql_value(fields[4])
        email = parse_mysql_value(fields[5])
        password_hash = parse_mysql_value(fields[2])
        lastlogin = parse_mysql_value(fields[8])
        login_count = parse_mysql_value(fields[10])
        active_user = parse_mysql_value(fields[9])
        # send_statement not in V1, default to 'n'
        
        # Generate INSERT
        insert = f"""INSERT INTO staging.v1_restaurant_admin_users (
    legacy_admin_id, legacy_v1_restaurant_id, fname, lname, email,
    password_hash, lastlogin, login_count, active_user, send_statement,
    created_at, updated_at
) VALUES (
    {legacy_admin_id}, {legacy_restaurant_id}, {fname}, {lname}, {email},
    {password_hash}, {lastlogin}, {login_count}, {active_user}, 'n',
    NULL, NULL
);"""
        
        sql_output.append(insert)
        processed += 1
        
        if processed % 50 == 0:
            print(f"  Processed {processed} records...", end='\r')
    
    except Exception as e:
        print(f"\n  ⚠️  Error parsing record: {e}")
        skipped += 1

print(f"\n[OK] Processed {processed} records")
if skipped > 0:
    print(f"[WARN] Skipped {skipped} records")
print()

sql_output.append("")
sql_output.append("COMMIT;")
sql_output.append("")
sql_output.append("-- Verification")
sql_output.append("SELECT COUNT(*) AS total_loaded FROM staging.v1_restaurant_admin_users;")

# Write output
output_file = "Database/Restaurant Management Entity/restaurant admins/step1b_insert_statements.sql"
print(f"[5/5] Writing to {output_file}...")
with open(output_file, 'w', encoding='utf-8') as f:
    f.write('\n'.join(sql_output))

print(f"[OK] SQL file generated: {output_file}")
print()
print("=" * 80)
print("  SUMMARY")
print("=" * 80)
print(f"  Total records found:    {len(records_raw)}")
print(f"  Successfully processed: {processed}")
print(f"  Skipped:                {skipped}")
print(f"  Output file:            {output_file}")
print("=" * 80)
print()
print("[READY] Execute with Supabase MCP!")
print()
print("[NEXT] Execute the generated SQL file using Supabase MCP")

