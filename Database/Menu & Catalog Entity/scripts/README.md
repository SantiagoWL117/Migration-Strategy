# Menu & Catalog Data Extraction Scripts

**Purpose**: Convert SQL dump files to CSV format for staging table creation  
**Phase**: Pre-Phase 2 (Data Extraction)  
**Date**: 2025-01-08

---

## ğŸ¯ Objective

Transform all 17 SQL dump files to CSV format while **excluding BLOB columns** identified in the BLOB analysis. This ensures:
1. Accurate staging table mapping
2. BLOB data handled separately in Phase 4
3. Clean CSV data for Supabase import

---

## ğŸ“‹ BLOB Columns Excluded

| Table | Excluded Columns | Reason |
|-------|------------------|--------|
| `menuca_v1_menu` | `hideOnDays` | BLOB Case #1 - Day availability rules |
| `menuca_v1_menuothers` | `content` | BLOB Case #2 - Modifier pricing |
| `menuca_v1_ingredient_groups` | `item`, `price` | BLOB Case #3 - Ingredient lists with pricing |
| `menuca_v1_combo_groups` | `dish`, `options`, `group` | BLOB Case #4 - Combo configurations (3 BLOBs) |

**Total BLOB columns excluded**: 7 columns across 4 tables

---

## ğŸ› ï¸ Scripts

### 1. `convert_dumps_to_csv.py` (RECOMMENDED)

**Python 3 script** - More robust SQL parsing

**Features**:
- Handles complex SQL INSERT statements
- Properly escapes CSV values
- Skips BLOB columns automatically
- Progress indicators
- Error handling and logging

**Requirements**:
- Python 3.7+
- No external dependencies (uses standard library)

**Usage**:
```bash
# From the scripts directory
python convert_dumps_to_csv.py

# Or from project root
python "Database/Menu & Catalog Entity/scripts/convert_dumps_to_csv.py"
```

---

### 2. `convert_all_dumps_to_csv.ps1` (ALTERNATIVE)

**PowerShell script** - For Windows environments

**Features**:
- Native Windows support
- Same BLOB exclusion logic
- CSV output with proper escaping
- Log file creation

**Requirements**:
- PowerShell 5.1+ or PowerShell Core 7+

**Usage**:
```powershell
# From the scripts directory
.\convert_all_dumps_to_csv.ps1

# Or from project root
& "Database\Menu & Catalog Entity\scripts\convert_all_dumps_to_csv.ps1"
```

---

## ğŸ“‚ Directory Structure

```
Database/Menu & Catalog Entity/
â”œâ”€â”€ dumps/                    # Source SQL dump files (17 files)
â”‚   â”œâ”€â”€ menuca_v1_courses.sql
â”‚   â”œâ”€â”€ menuca_v1_menu.sql
â”‚   â”œâ”€â”€ menuca_v1_menuothers.sql
â”‚   â”œâ”€â”€ menuca_v1_ingredients.sql
â”‚   â”œâ”€â”€ menuca_v1_ingredient_groups.sql
â”‚   â”œâ”€â”€ menuca_v1_combo_groups.sql
â”‚   â”œâ”€â”€ menuca_v1_combos.sql
â”‚   â”œâ”€â”€ menuca_v2_global_courses.sql
â”‚   â”œâ”€â”€ menuca_v2_global_ingredients.sql
â”‚   â”œâ”€â”€ menuca_v2_restaurants_courses.sql
â”‚   â”œâ”€â”€ menuca_v2_restaurants_dishes.sql
â”‚   â”œâ”€â”€ menuca_v2_restaurants_dishes_customization.sql
â”‚   â”œâ”€â”€ menuca_v2_restaurants_ingredients.sql
â”‚   â”œâ”€â”€ menuca_v2_restaurants_ingredient_groups.sql
â”‚   â”œâ”€â”€ menuca_v2_restaurants_ingredient_groups_items.sql
â”‚   â”œâ”€â”€ menuca_v2_restaurants_combo_groups.sql
â”‚   â””â”€â”€ menuca_v2_restaurants_combo_groups_items.sql
â”‚
â”œâ”€â”€ CSV/                      # Output CSV files (created by scripts)
â”‚   â”œâ”€â”€ menuca_v1_courses.csv
â”‚   â”œâ”€â”€ menuca_v1_menu.csv              # BLOB column excluded
â”‚   â”œâ”€â”€ menuca_v1_menuothers.csv        # BLOB column excluded
â”‚   â”œâ”€â”€ menuca_v1_ingredients.csv
â”‚   â”œâ”€â”€ menuca_v1_ingredient_groups.csv # BLOB columns excluded
â”‚   â”œâ”€â”€ menuca_v1_combo_groups.csv      # BLOB columns excluded
â”‚   â””â”€â”€ ... (all 17 CSV files)
â”‚
â””â”€â”€ scripts/                  # Conversion scripts (this directory)
    â”œâ”€â”€ README.md             # This file
    â”œâ”€â”€ convert_dumps_to_csv.py        # Python script (recommended)
    â”œâ”€â”€ convert_all_dumps_to_csv.ps1   # PowerShell script (alternative)
    â””â”€â”€ conversion_log.txt             # Log file (created after run)
```

---

## âœ… Expected Output

After running either script:

1. **CSV directory created**: `Database/Menu & Catalog Entity/CSV/`
2. **17 CSV files generated** (one per dump file)
3. **Log file**: `conversion_log.txt` with details
4. **Console output**: Progress and summary

### Sample Console Output:
```
=== Menu & Catalog SQL to CSV Conversion ===
Dumps Directory: .../dumps
CSV Directory: .../CSV

Found 17 dump files

ğŸ”„ Processing: menuca_v1_courses
  ğŸ“Š Columns: 8 (after excluding BLOBs)
    âœ“ Column: id
    âœ“ Column: name
    âœ“ Column: restaurant
    ...
    â†’ Processed 1000 rows...
    â†’ Processed 2000 rows...
  âœ… Converted 12924 rows to CSV

ğŸ”„ Processing: menuca_v1_menu
  ğŸ“‹ Excluding BLOB columns: hideOnDays
  ğŸ“Š Columns: 72 (after excluding BLOBs)
    âœ“ Column: id
    âœ“ Column: course
    â© Skipping BLOB column: hideOnDays
    ...
  âœ… Converted 117666 rows to CSV

...

=== Conversion Summary ===
Total Files: 17
âœ… Successful: 17
âŒ Failed: 0

CSV files: .../CSV

ğŸ‰ All dumps converted successfully!
```

---

## ğŸ” Validation

After conversion, verify:

1. **CSV file count**: Should have 17 CSV files
2. **Headers match**: Each CSV should have column headers
3. **BLOB columns absent**: Excluded columns should not appear in CSV
4. **Row counts**: Use `wc -l` (Linux/Mac) or PowerShell to count rows

### PowerShell Validation:
```powershell
# Count CSV files
Get-ChildItem "Database\Menu & Catalog Entity\CSV\*.csv" | Measure-Object

# Check row counts
Get-ChildItem "Database\Menu & Catalog Entity\CSV\*.csv" | ForEach-Object {
    $lineCount = (Get-Content $_.FullName | Measure-Object -Line).Lines
    [PSCustomObject]@{
        File = $_.Name
        Rows = $lineCount - 1  # Subtract header
    }
} | Format-Table -AutoSize
```

### Verify BLOB columns excluded:
```powershell
# Check menuca_v1_menu.csv does NOT have hideOnDays
$headers = (Get-Content "Database\Menu & Catalog Entity\CSV\menuca_v1_menu.csv" -First 1)
if ($headers -notmatch "hideOnDays") {
    Write-Host "âœ… hideOnDays correctly excluded" -ForegroundColor Green
} else {
    Write-Host "âŒ hideOnDays found in CSV!" -ForegroundColor Red
}
```

---

## ğŸ› Troubleshooting

### Issue: "No SQL dump files found"
**Solution**: Ensure you're running from the correct directory or update paths

### Issue: "Permission denied"
**Solution**: 
- Python: `chmod +x convert_dumps_to_csv.py`
- PowerShell: Run as Administrator or adjust execution policy

### Issue: "UnicodeDecodeError"
**Solution**: Script handles encoding automatically, but ensure SQL dumps are UTF-8

### Issue: "Row count mismatch"
**Solution**: This is expected when excluding BLOB columns - CSV will have fewer columns than SQL

---

## ğŸ“Š Next Steps

After CSV conversion:

1. âœ… **Phase 2**: Create staging tables matching CSV headers
2. âœ… **Phase 2**: Import CSV files to staging via Supabase
3. â³ **Phase 3**: Data quality assessment
4. â³ **Phase 4**: BLOB deserialization (handle excluded columns)
5. â³ **Phase 5**: Transform and load to menuca_v3

---

## ğŸ“ Notes

- **BLOB data NOT lost**: Excluded columns remain in SQL dumps for Phase 4 processing
- **CSV for staging only**: These CSV files are for accurate staging table creation
- **Phase 4 will deserialize BLOBs**: Python scripts will parse BLOB data separately
- **Clean data approach**: Staging â†’ Transform â†’ Validate â†’ Load

---

**Status**: â³ Ready to run  
**Next Action**: Execute `convert_dumps_to_csv.py`  
**Estimated Time**: 2-5 minutes for all 17 files




